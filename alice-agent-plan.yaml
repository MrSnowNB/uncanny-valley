# ALICE IN CYBERLAND - AI-FIRST EXECUTION PLAN
# Coding Agent Workflow with Gated Validation Protocol
# Version: 1.0.0 - Living Document
# Last Updated: 2025-10-26T10:25:00-04:00

# ============================================================================
# META: LIVING DOCUMENT STRUCTURE
# ============================================================================

document_metadata:
  version: "1.0.0"
  project_name: "Alice in Cyberland - POC Chatbot"
  execution_model: "AI-First with human-in-the-loop gate validation"
  coding_agent: "VSCode + Continue + Ollama"
  target_platform: "Z8 Workstation â†’ Cloud deployment ready"

  hardware_requirements:
    minimum:
      ram: "16 GB"
      gpu: "NVIDIA with 4GB VRAM (optional, falls back to CPU)"
      disk: "10 GB free"
      python: "3.10+"
    recommended:
      ram: "32 GB"
      gpu: "NVIDIA RTX 4090 or equivalent with 24GB VRAM and CUDA 12.1+"
      disk: "50 GB SSD"
  fallback_options:
    no_gpu: "Install CPU-only PyTorch: pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cpu"
    no_cuda: "Use CUDA 11.8 wheels if 12.1 unavailable: --index-url https://download.pytorch.org/whl/cu118"
    low_memory: "Enable attention optimizations, reduce model batch sizes"
  
  changelog:
    - version: "1.0.0"
      date: "2025-10-26"
      changes: ["Initial AI-First execution plan with 7 video clips", "Phase R0 Remediation: Filename standardization, logging infrastructure, hardware requirements added"]
      
  progress_tracking:
    overall_completion: 55
    tasks_completed: 17
    tasks_total: 25
    gates_passed: 6
    gates_total: 8
    errors_encountered: 1
    human_interventions: 0

# ============================================================================
# PROJECT ASSETS INVENTORY
# ============================================================================

assets:
  video_clips:
    location: "data/video_clips/"
    total_count: 7
    format: "MP4"
    duration: "5 seconds each"
    
    files:
      - filename: "idle-loop.mp4"
        state: "idle"
        has_audio: false
        description: "Default rest state, subtle breathing"
        
      - filename: "it-is-great-to-see-you-again.mp4"
        state: "greeting"
        has_audio: true
        description: "Welcome gesture, warm smile"
        
      - filename: "reading-computer-screen.mp4"
        state: "listening"
        has_audio: false
        description: "Focused look, tracking user input"
        
      - filename: "speaking-neutral.mp4"
        state: "neutral_speaking"
        has_audio: true
        description: "Calm talking animation"
        
      - filename: "thats-wonderful-to-hear.mp4"
        state: "friendly_speaking"
        has_audio: true
        description: "Positive affirmation, smiling"
        
      - filename: "concerned-deep-breath.mp4"
        state: "empathetic"
        has_audio: true
        description: "Reflective, empathetic response"
        
      - filename: "see-you-later.mp4"
        state: "farewell"
        has_audio: true
        description: "Gentle closing gesture"
  
  voice_model:
    current: "XTTS-v2 default English female"
    replacement_ready: true
    custom_voice_path: "data/alice_voice_custom.wav"
    notes: "Using free XTTS voice for POC, will swap for actor voice later"

# ============================================================================
# PHASE 0: ENVIRONMENT SETUP
# ============================================================================

phase_0_setup:
  phase_id: "P0"
  name: "Environment Setup & Dependencies"
  duration_estimate: "1 hour"
  status: "completed"
  completion: 100
  
  tasks:
    - task_id: "T0.1"
      name: "Verify project structure"
      priority: "critical"
      estimated_time: "5 minutes"
      
      steps:
        - step_id: "T0.1.1"
          action: "Check if VSCode workspace is open"
          command: "pwd"
          validation: "Output contains 'alice_cyberland' or project root"
          on_failure:
            action: "escalate"
            message: "Agent must be in project root directory"
        
        - step_id: "T0.1.2"
          action: "Verify video clips exist"
          command: "ls -la data/video_clips/*.mp4 | wc -l"
          validation: "Output is 7"
          on_failure:
            action: "escalate"
            message: "Expected 7 video clips, found different count"
        
        - step_id: "T0.1.3"
          action: "Create missing directories"
          command: |
            mkdir -p data/{video_clips,scripts,voice_samples}
            mkdir -p outputs/{audio,video,temp}
            mkdir -p src
            mkdir -p templates
            mkdir -p logs
            mkdir -p reports/{gates,daily,errors}
          validation: "All directories exist"
          on_failure:
            action: "retry"
            max_retries: 2
      
      gate: "GATE_0.1"
      gate_validation:
        - assertion: "Project structure complete"
          test: "test -d data && test -d src && test -d templates && test -d outputs"
          criticality: "critical"
        
        - assertion: "All 7 video clips present"
          test: "[ $(ls -1 data/video_clips/*.mp4 2>/dev/null | wc -l) -eq 7 ]"
          criticality: "critical"
      
      on_gate_pass:
        - "Log success to reports/gates/gate_0.1_passed.yaml"
        - "Update progress.gates_passed += 1"
        - "Proceed to T0.2"
      
      on_gate_fail:
        - "Log failure to reports/errors/gate_0.1_failed.yaml"
        - "Escalate to human with error context"
        - "Do NOT proceed to next task"
    
    - task_id: "T0.2"
      name: "Install Python dependencies"
      priority: "critical"
      estimated_time: "15 minutes"
      dependencies: ["T0.1"]
      
      steps:
        - step_id: "T0.2.1"
          action: "Check Python version"
          command: "python3 --version"
          validation: "Output contains 'Python 3.10' or 'Python 3.11'"
          on_failure:
            action: "escalate"
            message: "Python 3.10+ required"
        
        - step_id: "T0.2.2"
          action: "Create virtual environment"
          command: "python3 -m venv venv"
          validation: "test -d venv/bin/activate"
          on_failure:
            action: "retry"
            max_retries: 1
        
        - step_id: "T0.2.3"
          action: "Activate virtual environment"
          command: "source venv/bin/activate"
          validation: "echo $VIRTUAL_ENV | grep venv"
          on_failure:
            action: "check_troubleshooting"
            error_id: "ERR_VENV_ACTIVATION"
        
        - step_id: "T0.2.4"
          action: "Install core dependencies"
          command: |
            pip install --upgrade pip
            pip install fastapi==0.109.0 uvicorn[standard]==0.27.0
            pip install websockets==12.0 python-multipart==0.0.9
            pip install pyyaml requests jinja2
          timeout: 300
          validation: "pip list | grep -E '(fastapi|uvicorn|websockets)'"
          on_failure:
            action: "retry"
            max_retries: 2
        
        - step_id: "T0.2.5"
          action: "Install AI/ML dependencies"
          command: |
            pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
            pip install pyttsx3
            pip install opencv-python librosa soundfile
          timeout: 600
          validation: "python -c 'import torch; import pyttsx3; print(torch.cuda.is_available())'"
          expected: "True"
          on_failure:
            action: "check_troubleshooting"
            error_id: "ERR_PYTORCH_INSTALL"
      
      gate: "GATE_0.2"
      gate_validation:
        - assertion: "Virtual environment active"
          test: "[ -n \"$VIRTUAL_ENV\" ]"
          criticality: "critical"
        
        - assertion: "FastAPI installed"
          test: "pip show fastapi | grep -q Version"
          criticality: "critical"
        
        - assertion: "pyttsx3 installed"
          test: "python -c 'import pyttsx3'"
          criticality: "critical"
        
        - assertion: "PyTorch CUDA available"
          test: "python -c 'import torch; assert torch.cuda.is_available()'"
          criticality: "high"
      
      on_gate_pass:
        - "Log to reports/gates/gate_0.2_passed.yaml"
        - "Update progress.gates_passed += 1"
      
      on_gate_fail:
        - "Generate error report with pip list output"
        - "Check ERR_PYTORCH_INSTALL in troubleshooting docs"
        - "Escalate if retries exhausted"
    
    - task_id: "T0.3"
      name: "Start Ollama service"
      priority: "high"
      estimated_time: "10 minutes"
      dependencies: ["T0.2"]
      
      steps:
        - step_id: "T0.3.1"
          action: "Check if Ollama is installed"
          command: "which ollama"
          validation: "Output contains '/bin/ollama' or '/usr/local/bin/ollama'"
          on_failure:
            action: "install"
            install_command: "curl -fsSL https://ollama.com/install.sh | sh"
        
        - step_id: "T0.3.2"
          action: "Start Ollama service"
          command: "ollama serve > logs/ollama.log 2>&1 &"
          validation: "sleep 3 && pgrep -x ollama"
          on_failure:
            action: "check_troubleshooting"
            error_id: "ERR_OLLAMA_START"
        
        - step_id: "T0.3.3"
          action: "Pull Llama 3.1 model"
          command: "ollama pull llama3.1:8b-instruct-q4_K_M"
          timeout: 600
          validation: "ollama list | grep llama3.1"
          on_failure:
            action: "retry"
            max_retries: 2
        
        - step_id: "T0.3.4"
          action: "Test Ollama API"
          command: |
            curl -s http://localhost:11434/api/generate -d '{
              "model": "llama3.1:8b-instruct-q4_K_M",
              "prompt": "Say hello in 3 words.",
              "stream": false
            }' | grep response
          validation: "Output contains valid JSON response"
          on_failure:
            action: "check_troubleshooting"
            error_id: "ERR_OLLAMA_API"
      
      gate: "GATE_0.3"
      gate_validation:
        - assertion: "Ollama service running"
          test: "pgrep -x ollama > /dev/null"
          criticality: "critical"
        
        - assertion: "Llama 3.1 model available"
          test: "ollama list | grep -q llama3.1"
          criticality: "critical"
        
        - assertion: "Ollama API responsive"
          test: "curl -s http://localhost:11434/api/tags | grep -q models"
          criticality: "critical"
      
      on_gate_pass:
        - "Log to reports/gates/gate_0.3_passed.yaml"
        - "Mark Phase 0 complete"
      
      on_gate_fail:
        - "Kill any rogue Ollama processes: pkill ollama"
        - "Check port 11434 availability: lsof -i :11434"
        - "Escalate with full error context"

# ============================================================================
# PHASE 1: VIDEO MANIFEST & STATE MAPPING
# ============================================================================

phase_1_manifest:
  phase_id: "P1"
  name: "Create Video Manifest & State Machine"
  duration_estimate: "30 minutes"
  status: "pending"
  completion: 0
  dependencies: ["phase_0_setup"]
  
  tasks:
    - task_id: "T1.1"
      name: "Generate video manifest YAML"
      priority: "critical"
      estimated_time: "10 minutes"
      
      steps:
        - step_id: "T1.1.1"
          action: "Create video_manifest.yaml"
          file_to_create: "data/video_manifest.yaml"
          content: |
            # Alice in Cyberland - Video State Manifest
            # Maps chatbot states to video clip filenames
            
            character:
              name: "Alice"
              personality: "Lyra (curious, empathetic guide)"
              version: "1.0.0"
            
            video_clips:
              idle:
                file: "idle-loop.mp4"
                duration: 5
                loop: true
                has_audio: false
                description: "Default rest state"
              
              greeting:
                file: "it-is-great-to-see-you-again.mp4"
                duration: 5
                loop: false
                has_audio: true
                description: "Welcome user"
              
              listening:
                file: "reading-computer-screen.mp4"
                duration: 5
                loop: true
                has_audio: false
                description: "User typing or speaking"
              
              neutral_speaking:
                file: "speaking-neutral.mp4"
                duration: 5
                loop: false
                has_audio: true
                description: "Standard response delivery"
              
              friendly_speaking:
                file: "thats-wonderful-to-hear.mp4"
                duration: 5
                loop: false
                has_audio: true
                description: "Positive, enthusiastic response"
              
              empathetic:
                file: "concerned-deep-breath.mp4"
                duration: 5
                loop: false
                has_audio: true
                description: "Reflective, empathetic moment"
              
              farewell:
                file: "see-you-later.mp4"
                duration: 5
                loop: false
                has_audio: true
                description: "Closing interaction"
            
            state_transitions:
              default: "idle"
              on_user_input: "listening"
              on_ai_thinking: "listening"
              on_positive_response: "friendly_speaking"
              on_neutral_response: "neutral_speaking"
              on_empathy_needed: "empathetic"
              on_farewell: "farewell"
              after_response: "idle"
            
            voice_settings:
              current_model: "XTTS-v2 default"
              sample_rate: 22050
              language: "en"
              replaceable: true
              custom_voice_path: null  # Will be updated when voice actor audio available
          
          validation: "test -f data/video_manifest.yaml"
          on_failure:
            action: "retry"
            max_retries: 1
        
        - step_id: "T1.1.2"
          action: "Validate manifest YAML syntax"
          command: "python -c 'import yaml; yaml.safe_load(open(\"data/video_manifest.yaml\"))'"
          validation: "Exit code 0"
          on_failure:
            action: "check_troubleshooting"
            error_id: "ERR_YAML_SYNTAX"
      
      gate: "GATE_1.1"
      gate_validation:
        - assertion: "Manifest file exists"
          test: "test -f data/video_manifest.yaml"
          criticality: "critical"
        
        - assertion: "All 7 video states mapped"
          test: "grep -c 'file:' data/video_manifest.yaml | grep 7"
          criticality: "critical"
        
        - assertion: "YAML is valid"
          test: "python -c 'import yaml; yaml.safe_load(open(\"data/video_manifest.yaml\"))'"
          criticality: "critical"
      
      on_gate_pass:
        - "Log to reports/gates/gate_1.1_passed.yaml"
        - "Proceed to T1.2"
      
      on_gate_fail:
        - "Log syntax errors to reports/errors/manifest_syntax_error.yaml"
        - "Escalate to human"

# ============================================================================
# PHASE 2: VOICE ENGINE IMPLEMENTATION
# ============================================================================

phase_2_voice:
  phase_id: "P2"
  name: "Implement TTS Voice Engine"
  duration_estimate: "2 hours"
  status: "completed"
  completion: 100
  dependencies: ["phase_1_manifest"]
  
  tasks:
    - task_id: "T2.1"
      name: "Create TTS engine module"
      priority: "critical"
      estimated_time: "45 minutes"
      
      steps:
        - step_id: "T2.1.1"
          action: "Generate src/tts_engine.py"
          file_to_create: "src/tts_engine.py"
          content: |
            \"\"\"
            XTTS-v2 Text-to-Speech Engine for Alice
            Supports default voice and custom voice cloning
            \"\"\"
            
            import os
            import uuid
            from pathlib import Path
            from TTS.api import TTS
            import yaml
            
            class AliceTTSEngine:
                def __init__(self, manifest_path="data/video_manifest.yaml"):
                    \"\"\"Initialize TTS engine with video manifest config\"\"\"
                    self.manifest = self._load_manifest(manifest_path)
                    self.model_name = "tts_models/multilingual/multi-dataset/xtts_v2"
                    self.device = "cuda:0"  # Z8 workstation
                    self.tts = None
                    self._initialize_model()
                
                def _load_manifest(self, path):
                    \"\"\"Load video manifest YAML\"\"\"
                    with open(path, 'r') as f:
                        return yaml.safe_load(f)
                
                def _initialize_model(self):
                    \"\"\"Load XTTS-v2 model into GPU memory\"\"\"
                    print(f"Loading TTS model: {self.model_name}")
                    self.tts = TTS(self.model_name).to(self.device)
                    print("âœ… TTS model loaded successfully")
                
                def synthesize(self, text, output_dir="outputs/audio", use_custom_voice=False):
                    \"\"\"
                    Generate speech audio from text
                    
                    Args:
                        text: Text to synthesize
                        output_dir: Directory to save audio file
                        use_custom_voice: If True, use custom voice from manifest
                    
                    Returns:
                        Path to generated audio file
                    \"\"\"
                    # Create output directory if needed
                    Path(output_dir).mkdir(parents=True, exist_ok=True)
                    
                    # Generate unique filename
                    audio_filename = f"alice_response_{uuid.uuid4().hex[:8]}.wav"
                    audio_path = os.path.join(output_dir, audio_filename)
                    
                    # Get voice settings from manifest
                    voice_settings = self.manifest.get('voice_settings', {})
                    custom_voice_path = voice_settings.get('custom_voice_path')
                    
                    # Synthesize
                    if use_custom_voice and custom_voice_path and os.path.exists(custom_voice_path):
                        print(f"Using custom voice: {custom_voice_path}")
                        self.tts.tts_to_file(
                            text=text,
                            speaker_wav=custom_voice_path,
                            language="en",
                            file_path=audio_path
                        )
                    else:
                        # Use default XTTS voice
                        print("Using default XTTS voice")
                        self.tts.tts_to_file(
                            text=text,
                            language="en",
                            file_path=audio_path
                        )
                    
                    print(f"âœ… Audio generated: {audio_path}")
                    return audio_path
                
                def test_voice(self, test_text="Hello, I'm Alice, your guide to Cyberland."):
                    \"\"\"Test TTS engine with sample text\"\"\"
                    print(f"Testing TTS with: {test_text}")
                    audio_path = self.synthesize(test_text, output_dir="outputs/test")
                    print(f"Test audio saved to: {audio_path}")
                    return audio_path
            
            # Test if run directly
            if __name__ == "__main__":
                engine = AliceTTSEngine()
                engine.test_voice()
          
          validation: "test -f src/tts_engine.py"
          on_failure:
            action: "retry"
            max_retries: 1
        
        - step_id: "T2.1.2"
          action: "Test TTS engine initialization"
          command: "python src/tts_engine.py"
          timeout: 120
          validation: "grep 'âœ… TTS model loaded' in output"
          on_failure:
            action: "check_troubleshooting"
            error_id: "ERR_TTS_LOAD"
        
        - step_id: "T2.1.3"
          action: "Verify audio generation"
          command: "ls -la outputs/test/*.wav"
          validation: "At least one .wav file exists"
          on_failure:
            action: "check_troubleshooting"
            error_id: "ERR_AUDIO_GEN"
      
      gate: "GATE_2.1"
      gate_validation:
        - assertion: "TTS engine file created"
          test: "test -f src/tts_engine.py"
          criticality: "critical"
        
        - assertion: "TTS model loads without errors"
          test: "python -c 'from src.tts_engine import AliceTTSEngine; engine = AliceTTSEngine()'"
          criticality: "critical"
        
        - assertion: "Test audio generated successfully"
          test: "[ $(find outputs/test -name '*.wav' | wc -l) -gt 0 ]"
          criticality: "critical"
        
        - assertion: "Audio file is valid (>1KB)"
          test: "[ $(find outputs/test -name '*.wav' -size +1k | wc -l) -gt 0 ]"
          criticality: "high"
      
      on_gate_pass:
        - "Log to reports/gates/gate_2.1_passed.yaml"
        - "Save test audio path for demo"
        - "Proceed to Phase 3"
      
      on_gate_fail:
        - "Capture full error logs"
        - "Check GPU memory: nvidia-smi"
        - "Escalate with diagnostic info"

# ============================================================================
# TROUBLESHOOTING REFERENCE
# ============================================================================

troubleshooting:
  errors:
    - error_id: "ERR_VENV_ACTIVATION"
      description: "Virtual environment failed to activate"
      symptoms:
        - "$VIRTUAL_ENV is empty"
        - "pip commands install to system Python"
      recovery_steps:
        - "Deactivate any existing venv: deactivate"
        - "Remove corrupted venv: rm -rf venv"
        - "Recreate: python3 -m venv venv"
        - "Activate: source venv/bin/activate"
        - "Verify: echo $VIRTUAL_ENV"
      prevention: "Always check $VIRTUAL_ENV before pip commands"
    
    - error_id: "ERR_PYTORCH_INSTALL"
      description: "PyTorch installation fails or CUDA not detected"
      symptoms:
        - "torch.cuda.is_available() returns False"
        - "pip install torch fails"
      recovery_steps:
        - "Check GPU: nvidia-smi"
        - "Check CUDA version: nvcc --version"
        - "Install for CUDA 12.1: pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu121"
        - "Test: python -c 'import torch; print(torch.cuda.device_count())'"
      prevention: "Use exact CUDA-specific PyTorch wheel URL"
    
    - error_id: "ERR_OLLAMA_START"
      description: "Ollama service fails to start"
      symptoms:
        - "pgrep ollama returns nothing"
        - "Connection refused on port 11434"
      recovery_steps:
        - "Kill any zombie processes: pkill ollama"
        - "Check port: lsof -i :11434"
        - "Start manually: ollama serve &"
        - "Wait 5 seconds: sleep 5"
        - "Verify: curl http://localhost:11434/api/tags"
      prevention: "Add ollama serve to systemd or startup script"
    
    - error_id: "ERR_YAML_SYNTAX"
      description: "YAML manifest has syntax errors"
      symptoms:
        - "yaml.safe_load() raises exception"
        - "Indentation errors"
      recovery_steps:
        - "Validate online: https://www.yamllint.com/"
        - "Check indentation (use spaces, not tabs)"
        - "Verify colons have space after: 'key: value'"
        - "Check for duplicate keys"
      prevention: "Use YAML extension in VSCode with validation"
    
    - error_id: "ERR_TTS_LOAD"
      description: "XTTS model fails to load"
      symptoms:
        - "TTS() constructor raises exception"
        - "CUDA out of memory"
      recovery_steps:
        - "Check GPU memory: nvidia-smi"
        - "Clear cache: python -c 'import torch; torch.cuda.empty_cache()'"
        - "Try different GPU: device='cuda:1'"
        - "Check model download: ls ~/.local/share/tts/"
      prevention: "Pre-download models, monitor GPU memory"
    
    - error_id: "ERR_AUDIO_GEN"
      description: "Audio file generation fails"
      symptoms:
        - "No .wav file created"
        - "Empty audio file (0 bytes)"
      recovery_steps:
        - "Check output directory exists: ls outputs/test"
        - "Check write permissions: ls -la outputs/"
        - "Try absolute path for output"
        - "Check disk space: df -h"
      prevention: "Create output dirs before generation"

# ============================================================================
# LIVING DOCUMENT: PROGRESS TRACKING
# ============================================================================

progress_log:
  format: "Append-only log of all task executions"
  location: "reports/daily/progress_<date>.yaml"
  
  entry_template:
    timestamp: "ISO 8601"
    task_id: "TX.Y"
    status: "started|completed|failed"
    duration_seconds: 0
    error_id: null
    notes: ""
  
  example_entries:
    - timestamp: "2025-10-26T10:25:00-04:00"
      task_id: "T0.1"
      status: "completed"
      duration_seconds: 45
      error_id: null
      notes: "All 7 video clips verified"

  logging_integration:
    script_path: "scripts/progress_logger.py"
    usage_examples:
      - "Start task: python scripts/progress_logger.py log_progress T0.1 started"
      - "Complete: python scripts/progress_logger.py log_progress T0.1 completed 45"
      - "Failed: python scripts/progress_logger.py log_progress T0.1 failed 30 ERR_VENV_ACTIVATION 'Virtual env failed'"
    automation_notes: "Integrate calls into command sequences using && operator"

# ============================================================================
# GATE VALIDATION PROTOCOL
# ============================================================================

gate_validation_protocol:
  rules:
    - "All 'critical' assertions MUST pass (100%)"
    - "All 'high' assertions MUST pass (100%)"
    - "'medium' assertions: 80% pass rate acceptable"
    - "'low' assertions: advisory only"
  
  on_gate_failure:
    max_retries: 3
    retry_strategy:
      attempt_1: "Auto-retry with same parameters"
      attempt_2: "Apply troubleshooting steps if error_id known"
      attempt_3: "Escalate to human with full diagnostic package"
    
    diagnostic_package:
      - "Full error logs"
      - "Environment state (pip list, env vars)"
      - "System resources (nvidia-smi, df -h)"
      - "Last 50 lines of all logs"
      - "Current task YAML context"
  
  on_gate_success:
    - "Update progress tracker"
    - "Create checkpoint (git tag gate_X.Y)"
    - "Log gate metrics (duration, retry count)"
    - "Proceed to next task automatically"

# ============================================================================
# HUMAN INTERVENTION TRIGGERS
# ============================================================================

human_intervention:
  triggers:
    - "Any gate fails after 3 retries"
    - "Unknown error_id not in troubleshooting docs"
    - "Critical resource unavailable (GPU, disk space)"
    - "Manual step required (voice recording, API key)"
  
  notification_method: "Console alert + YAML report in reports/escalations/"
  
  escalation_report_template:
    escalation_id: "ESC_<timestamp>"
    severity: "critical|high|medium"
    task_context: "Full task YAML"
    error_summary: "Human-readable description"
    attempted_fixes: []
    recommended_action: ""
    wait_for_human: true

# ============================================================================
# NEXT PHASES (TO BE CREATED)
# ============================================================================

remaining_phases:
  - phase_id: "P3"
    name: "Chat Backend Implementation"
    tasks: ["FastAPI WebSocket server", "Ollama integration", "State machine"]
  
  - phase_id: "P4"
    name: "Web UI Development"
    tasks: ["HTML/CSS/JS chat interface", "Video player state switching", "Audio playback"]
  
  - phase_id: "P5"
    name: "Integration Testing"
    tasks: ["End-to-end chat flow", "Video state transitions", "Audio synchronization"]
  
  - phase_id: "P6"
    name: "Optional: Wav2Lip Lip-Sync"
    tasks: ["Install Wav2Lip", "Integrate with TTS", "Real-time mouth sync"]
